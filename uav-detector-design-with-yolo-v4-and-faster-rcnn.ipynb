{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7db29f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.00887,
     "end_time": "2023-11-06T17:02:42.709771",
     "exception": false,
     "start_time": "2023-11-06T17:02:42.700901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border: 10px solid #1976D2; border-radius: 15px; padding: 20px 20px 20px 20px; box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2); background-color: #f4f4f4;\">\n",
    "    <h2 style=\"font-size: 28px; font-weight: bold; color: #1976D2; text-align: center; border-bottom: 4px ridge #64B5F6; font-family: 'Georgia'; padding: 10px;\">Training a Faster RCNN X101 Detector</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d262eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T17:02:42.728686Z",
     "iopub.status.busy": "2023-11-06T17:02:42.728256Z",
     "iopub.status.idle": "2023-11-06T17:03:38.576091Z",
     "shell.execute_reply": "2023-11-06T17:03:38.574383Z"
    },
    "papermill": {
     "duration": 55.860959,
     "end_time": "2023-11-06T17:03:38.579420",
     "exception": false,
     "start_time": "2023-11-06T17:02:42.718461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.5 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.5\u001b[0m\u001b[31m\r\n",
      "\u001b[0mRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (0.29.35)\r\n",
      "Collecting pyyaml==5.1\r\n",
      "  Downloading PyYAML-5.1.tar.gz (274 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\r\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.1-cp310-cp310-linux_x86_64.whl size=44091 sha256=691c02571ce5146fb7b89b380b2bd42b6c9bf6cecef5ba4950c05af62b43c882\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/83/31/975b737609aba39a4099d471d5684141c1fdc3404f97e7f68a\r\n",
      "Successfully built pyyaml\r\n",
      "Installing collected packages: pyyaml\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0\r\n",
      "    Uninstalling PyYAML-6.0:\r\n",
      "      Successfully uninstalled PyYAML-6.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask 2023.7.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "distributed 2023.7.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "flax 0.7.0 requires PyYAML>=5.4.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "jupyter-events 0.6.3 requires pyyaml>=5.3, but you have pyyaml 5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.0.1 requires PyYAML<7,>=5.3, but you have pyyaml 5.1 which is incompatible.\r\n",
      "kubernetes 26.1.0 requires pyyaml>=5.4.1, but you have pyyaml 5.1 which is incompatible.\r\n",
      "pytorch-lightning 2.0.4 requires PyYAML>=5.4, but you have pyyaml 5.1 which is incompatible.\r\n",
      "ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pyyaml-5.1\r\n",
      "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\r\n",
      "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-jvi6_en7\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-jvi6_en7\r\n",
      "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0) (59.8.0)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0) (0.29.35)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0) (3.7.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\r\n",
      "Building wheels for collected packages: pycocotools\r\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=101559 sha256=b29bdc9f73883fd392b943ee4c7b71532a9ff565681dd2b2b2202df9db3c1845\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ore4qk17/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\r\n",
      "Successfully built pycocotools\r\n",
      "Installing collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0\r\n",
      "2.0.0+cpu False\n",
      "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\r\n",
      "Copyright (C) 2019 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Detectron2 Installation Process\n",
    "# cu101 must be installed as it is CUDA 10.1\n",
    "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
    "!pip install cython pyyaml==5.1\n",
    "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe955fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T17:03:38.607929Z",
     "iopub.status.busy": "2023-11-06T17:03:38.606703Z",
     "iopub.status.idle": "2023-11-06T17:03:41.607625Z",
     "shell.execute_reply": "2023-11-06T17:03:41.606093Z"
    },
    "papermill": {
     "duration": 3.019553,
     "end_time": "2023-11-06T17:03:41.610365",
     "exception": false,
     "start_time": "2023-11-06T17:03:38.590812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement detectron2==0.1.3 (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for detectron2==0.1.3\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# detectron2 setup\n",
    "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321e70e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T17:03:41.637330Z",
     "iopub.status.busy": "2023-11-06T17:03:41.635828Z",
     "iopub.status.idle": "2023-11-06T17:03:42.150614Z",
     "shell.execute_reply": "2023-11-06T17:03:42.147994Z"
    },
    "papermill": {
     "duration": 0.531104,
     "end_time": "2023-11-06T17:03:42.153156",
     "exception": true,
     "start_time": "2023-11-06T17:03:41.622052",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Runtime can be restarted in this section\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# detectron2 logger installation\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n\u001b[1;32m      5\u001b[0m setup_logger()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "# Runtime can be restarted in this section\n",
    "# detectron2 logger installation\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb399e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common libraries should be imported\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a729f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some common detectron2 features should be imported\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.catalog import DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cdec7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing Detectron2 Dataset\n",
    "!curl -L \"https://app.roboflow.com/ds/zi9LUNojmz?key=H5YnroNUmG\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"/content/train/_annotations.coco.json\", \"/content/train\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"/content/valid/_annotations.coco.json\", \"/content/valid\")\n",
    "register_coco_instances(\"my_dataset_test\", {}, \"/content/test/_annotations.coco.json\", \"/content/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03500e90",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading the training dataset\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2146b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training of Detectron2 Detector\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "        output_folder = \"coco_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e918616",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CNN architecture should be selected from modelzoo section: https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md#coco-object-detection-baselines\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Model zoo dan eğitim başlatılmalı\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 6000 #Modelin iterasyon sayısına göre overfit etmesi ya da başarının artma durumunun devam etme potansiyeline göre iterasyon sayısı ayarlanmalıdır\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2 #sınıf sayısı + 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9ac9f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The performance of the model should be checked on the Tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output\n",
    "\n",
    "#test evaluation\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0004999.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936498a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Inference from Detectron2 registered weights\n",
    "%ls ./output/\n",
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "\n",
    "for imageName in glob.glob('/content/test/*jpg'):\n",
    "  im = cv2.imread(imageName)\n",
    "  outputs = predictor(im)\n",
    "  v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=test_metadata, \n",
    "                scale=0.8\n",
    "                 )\n",
    "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "  cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535e050",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### YOLO v4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f239d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Cloning and installation of #Darknet library\n",
    "# clone darknet repo\n",
    "!git clone https://github.com/AlexeyAB/darknet\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822170e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change \"makefile\" to enable GPU and OPENCV\n",
    "%cd darknet\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
    "\n",
    "# darknet setup\n",
    "!make\n",
    "\n",
    "# Load pre-trained YOLO v4 weights\n",
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d6270",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def imShow(path):\n",
    "  import cv2\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "\n",
    "  image = cv2.imread(path)\n",
    "  height, width = image.shape[:2]\n",
    "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(18, 10)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0e9ed",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uploading files\n",
    "def upload():\n",
    "  from google.colab import files\n",
    "  uploaded = files.upload() \n",
    "  for name, data in uploaded.items():\n",
    "    with open(name, 'wb') as f:\n",
    "      f.write(data)\n",
    "      print ('saved file', name)\n",
    "\n",
    "# used for file download\n",
    "def download(path):\n",
    "  from google.colab import files\n",
    "  files.download(path)\n",
    "\n",
    "%cd ..\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# this step creates a symbolic link between “/content/gdrive/My\\ Drive/” and “/mydrive” extensions\n",
    "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
    "!ls /mydrive\n",
    "\n",
    "# return to the previous darknet folder to run the detection function\n",
    "%cd darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ce883",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border: 10px solid #1976D2; border-radius: 15px; padding: 20px 20px 20px 20px; box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2); background-color: #f4f4f4;\">\n",
    "    <h2 style=\"font-size: 28px; font-weight: bold; color: #1976D2; text-align: center; border-bottom: 4px ridge #64B5F6; font-family: 'Georgia'; padding: 10px;\">Training a YOLOv4 Detector</h2>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px;\">\n",
    "        <span style=\"font-size: 20px;\">#</span> How to Train a Custom YOLOv4 Detector:\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        To create a custom YOLOv4 detector, the following components are essential:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px; margin-left: 20px;\">\n",
    "        <li>Labeled Custom Dataset</li>\n",
    "        <li>Custom .cfg file</li>\n",
    "        <li>obj.data and obj.names files</li>\n",
    "        <li>train.txt file (test.txt is optional here as well)</li>\n",
    "    </ul>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px;\">\n",
    "        The next step is to transfer your custom dataset to the cloud virtual machine:\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5707e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /mydrive/yolov4\n",
    "\n",
    "# both datasets are copied to the root directory of the Colab virtual machine\n",
    "!cp /mydrive/yolov4/obj.zip ../\n",
    "!cp /mydrive/yolov4/test.zip ../\n",
    "\n",
    "# unzip in virtual machine\n",
    "!unzip ../obj.zip -d data/\n",
    "!unzip ../test.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d37f0c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Educational Design\n",
    "Step #u involves properly configuring your custom .cfg, obj.data, obj.names, train.txt and test.txt files.\n",
    "#It is important to configure all these files extremely carefully, as typos or minor errors can cause major problems in special training.\n",
    "#i) File with Cfg Extension\n",
    "#Copy the yolov4.cfg file to your Google Drive by running the cell below. This will allow us to edit it in a text editor.\n",
    "\n",
    "# download cfg to google drive and rename\n",
    "!cp cfg/yolov4-custom.cfg /mydrive/yolov4/yolov4-obj.cfg\n",
    "\n",
    "# to download to local machine (rename to yolov4-obj.cfg after downloading)\n",
    "download('cfg/yolov4-custom.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67fe31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border: 10px solid #1976D2; border-radius: 15px; padding: 20px 20px 20px 20px; box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2); background-color: #f4f4f4;\">\n",
    "    <h2 style=\"font-size: 28px; font-weight: bold; color: #1976D2; text-align: center; border-bottom: 4px ridge #64B5F6; font-family: 'Georgia'; padding: 10px;\">Customizing Your Configuration</h2>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px;\">\n",
    "        <span style=\"font-size: 20px;\">⚙️</span> In this step, you'll fine-tune your object detector's .cfg file to match your specific requirements:\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        If you've saved the .cfg file to Google Drive, navigate to your Google Drive and double-click on the yolov4-obj.cfg file. Choose \"Open with\" and select Text Editor to use the built-in tool.\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        For optimal results, consider setting batch = 64 and subdivisions = 16. If you encounter any issues, increase subdivisions to 32.\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        Customize the rest of the .cfg file based on the number of classes you are training your object detector for. Update the classes value in the YOLO layers and filters value in the convolutional layers before the YOLO layers, adjusting to (number of classes + 5) * 3.\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px;\">\n",
    "        Configure the following variables as follows:\n",
    "    </p>\n",
    "    <ul style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px; margin-left: 20px;\">\n",
    "        <li>width = 416</li>\n",
    "        <li>height = 416 (these values can be multiples of 32, with 416 being the standard; you can occasionally increase it, e.g., 608, for improved results, though it may slow down training)</li>\n",
    "        <li>max_batches = (# of classes) * 2000 (should not be less than 6000, e.g., 1, 2, and 3 classes should have 6000 iterations)</li>\n",
    "        <li>steps = 80% of max_batches, 90% of max_batches</li>\n",
    "        <li>filters = (number of classes + 5) * 3 (e.g., if you have 1 class, filters = 18; for 4 classes, filters = 27)</li>\n",
    "    </ul>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        Once configured, upload your customized .cfg file back to your cloud environment, such as your cloud virtual machine.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896b228",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!cp /mydrive/yolov4/yolov4-obj.cfg ./cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fcbe88",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border: 10px solid #1976D2; border-radius: 15px; padding: 20px 20px 20px 20px; box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2); background-color: #f4f4f4;\">\n",
    "    <h2 style=\"font-size: 28px; font-weight: bold; color: #1976D2; text-align: center; border-bottom: 4px ridge #64B5F6; font-family: 'Georgia'; padding: 10px;\">Setting Up obj.names and obj.data Files</h2>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px;\">\n",
    "        <span style=\"font-size: 20px;\">ii)</span> Create the obj.names and obj.data files to enable efficient model training and backup:\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        In a code or text editor, create a new file named obj.names. Each line in this file should correspond to a class name, in the same order as the classes in the vclasss.txt file created during the dataset creation step.\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        Additionally, create an obj.data file and populate it as follows:\n",
    "    </p>\n",
    "    <pre style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px; background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 5px; padding: 10px;\">\n",
    "classes = (number of classes)\n",
    "train = data/train.txt\n",
    "valid = data/test.txt\n",
    "names = data/obj.names\n",
    "backup = /content/drive/MyDrive/backup_folder/\n",
    "    </pre>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        The \"backup\" path specifies where the model weights will be saved during training. Create a backup folder on your Google Drive platform and adjust the path accordingly.\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px;\">\n",
    "        Finally, upload the obj.names and obj.data files to your cloud virtual machine.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1335bf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!cp /mydrive/yolov4/obj.names ./data\n",
    "!cp /mydrive/yolov4/obj.data  ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a74de",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "<div style=\"border: 10px solid #1976D2; border-radius: 15px; padding: 20px 20px 20px 20px; box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2); background-color: #f4f4f4;\">\n",
    "    <h2 style=\"font-size: 28px; font-weight: bold; color: #1976D2; text-align: center; border-bottom: 4px ridge #64B5F6; font-family: 'Georgia'; padding: 10px;\">Creating train.txt and test.txt Files</h2>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; padding: 10px;\">\n",
    "        <span style=\"font-size: 20px;\">iii)</span> Before you commence training your custom detector, you need to prepare the essential configuration files, train.txt and test.txt, which contain the relevant extensions to all training and validation images:\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        These files hold the keys to your custom detector's training process. They list the paths to all training and validation images, respectively.\n",
    "    </p>\n",
    "    <p style=\"font-size: 16px; font-family: Arial, sans-serif; line-height: 1.6; margin-left: 20px; padding: 10px;\">\n",
    "        To create these files, upload the create_train.py and create_test.py script files from your Google Drive to your cloud virtual machine.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c935831",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /mydrive/yolov4/generate_train.py ./\n",
    "!cp /mydrive/yolov4/generate_test.py ./\n",
    "\n",
    "!python generate_train.py\n",
    "!python generate_test.py\n",
    "\n",
    "!ls data/\n",
    "\n",
    "#Pre-trained weights are downloaded for learning transfer\n",
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056ec53",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Detector's Training\n",
    "\n",
    "# training of the special detector!\n",
    "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg yolov4.conv.137 -dont_show -map\n",
    "\n",
    "#After the training, run the command below to get a table showing how your model has worked throughout the training process. A graph of the average loss versus iterations is shown. A loss of less than 2% is targeted for the model to be effective.\n",
    "# show chart.png of how custom object detector did with training\n",
    "imShow('chart.png')\n",
    "\n",
    "\n",
    "#We can start the training from the last saved weights file so that there is no need to start over.\n",
    "# Start the tutorial from where it was last saved\n",
    "!./darknet detector train data/obj.data cfg/yolov4-obj.cfg /mydrive/yolov4/backup/yolov4-obj_last.weights -dont_show\n",
    "\n",
    "#Checking the Mean Average Precision (mAP) Value\n",
    "#If the tutorial wasn't run with the '-map- flag added, you can learn the map of the model after the tutorial. To see the mAP value for the file of that weight, run the following command on any of the weights saved from the training.!./darknet detector map data/obj.data cfg/yolov4-obj.cfg /mydrive/yolov4/backup/yolov4-obj_last.weights\n",
    "\n",
    "#Custom Object Detector Running for Picture\n",
    "# we need to set custom cfg file to test mode\n",
    "%cd cfg\n",
    "!sed -i 's/batch=64/batch=1/' yolov4-obj.cfg\n",
    "!sed -i 's/subdivisions=16/subdivisions=1/' yolov4-obj.cfg\n",
    "%cd ..\n",
    "\n",
    "# custom detector is run with this command (image uploaded to google drive platform for testing)\n",
    "!./darknet detector test data/obj.data cfg/yolov4-obj.cfg /mydrive/yolov4/backup/yolov4-obj_last.weights /mydrive/images/UAV8.jpg -thresh 0.3\n",
    "imShow('predictions.jpg')\n",
    "\n",
    "#Custom Object Detector Run for Video\n",
    "\n",
    "!./darknet detector demo data/obj.data cfg/yolov4-obj.cfg /mydrive/yolov4/backup/yolov4-obj_last.weights -dont_show /mydrive/videos/UAV3.mp4 -i 0 -out_filename /mydrive/videos/results3.avi\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.010077,
   "end_time": "2023-11-06T17:03:44.677791",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-06T17:02:28.667714",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
